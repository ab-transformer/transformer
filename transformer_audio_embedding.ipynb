{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline('feature-extraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(p([\"Hellow word!\", \"Hellow word!\"])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPRESSIONV2_DIR = Path('/impressionv2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = os.listdir(IMPRESSIONV2_DIR/'train')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spectrograms',\n",
       " 'audio_segments',\n",
       " 'fi_face_resnet18',\n",
       " 'openface',\n",
       " 'pyaa',\n",
       " 'egemaps',\n",
       " 'YbxdeEd7wq4.001.wav',\n",
       " 'frames',\n",
       " 'dynimgs']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(IMPRESSIONV2_DIR/'train'/dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/impressionv2/train/YbxdeEd7wq4.001/YbxdeEd7wq4.001.wav')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMPRESSIONV2_DIR/'train'/dirs[0]/'YbxdeEd7wq4.001.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import torch\n",
    "from transformers import Wav2Vec2Tokenizer, Wav2Vec2ForCTC, Wav2Vec2Model\n",
    "\n",
    "# load pretrained model\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "raw_model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_input, sampling_rate = sf.read(IMPRESSIONV2_DIR/'train'/dirs[0]/'YbxdeEd7wq4.001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "r = Resample(sampling_rate)\n",
    "audio_input = r.forward(torch.tensor(audio_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_values = tokenizer(audio_input, return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = tokenizer.decode(predicted_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = raw_model(input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([244832]),\n",
       " torch.Size([1, 244832]),\n",
       " torch.Size([1, 764, 32]),\n",
       " torch.Size([1, 764]),\n",
       " 268)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_input.shape, input_values.shape, logits.shape, predicted_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'Wav2Vec2ForCTC' object has no attribute 'linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-63b536c3a73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'Wav2Vec2ForCTC' object has no attribute 'linear'"
     ]
    }
   ],
   "source": [
    "model.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 764, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Layer (type:depth-idx)                                  Param #\n",
      "================================================================================\n",
      "├─Wav2Vec2Model: 1-1                                    --\n",
      "|    └─Wav2Vec2FeatureExtractor: 2-1                    --\n",
      "|    |    └─ModuleList: 3-1                             4,200,448\n",
      "|    └─Wav2Vec2FeatureProjection: 2-2                   --\n",
      "|    |    └─LayerNorm: 3-2                              1,024\n",
      "|    |    └─Linear: 3-3                                 393,984\n",
      "|    |    └─Dropout: 3-4                                --\n",
      "|    └─Wav2Vec2Encoder: 2-3                             --\n",
      "|    |    └─Wav2Vec2PositionalConvEmbedding: 3-5        4,719,488\n",
      "|    |    └─LayerNorm: 3-6                              1,536\n",
      "|    |    └─Dropout: 3-7                                --\n",
      "|    |    └─ModuleList: 3-8                             85,054,464\n",
      "├─Dropout: 1-2                                          --\n",
      "├─Linear: 1-3                                           24,608\n",
      "================================================================================\n",
      "Total params: 94,395,552\n",
      "Trainable params: 94,395,552\n",
      "Non-trainable params: 0\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "├─Wav2Vec2Model: 1-1                                    --\n",
       "|    └─Wav2Vec2FeatureExtractor: 2-1                    --\n",
       "|    |    └─ModuleList: 3-1                             4,200,448\n",
       "|    └─Wav2Vec2FeatureProjection: 2-2                   --\n",
       "|    |    └─LayerNorm: 3-2                              1,024\n",
       "|    |    └─Linear: 3-3                                 393,984\n",
       "|    |    └─Dropout: 3-4                                --\n",
       "|    └─Wav2Vec2Encoder: 2-3                             --\n",
       "|    |    └─Wav2Vec2PositionalConvEmbedding: 3-5        4,719,488\n",
       "|    |    └─LayerNorm: 3-6                              1,536\n",
       "|    |    └─Dropout: 3-7                                --\n",
       "|    |    └─ModuleList: 3-8                             85,054,464\n",
       "├─Dropout: 1-2                                          --\n",
       "├─Linear: 1-3                                           24,608\n",
       "================================================================================\n",
       "Total params: 94,395,552\n",
       "Trainable params: 94,395,552\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "├─Wav2Vec2FeatureExtractor: 1-1                    --\n",
      "|    └─ModuleList: 2-1                             --\n",
      "|    |    └─Wav2Vec2GroupNormConvLayer: 3-1        6,144\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-2      786,432\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-3      786,432\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-4      786,432\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-5      786,432\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-6      524,288\n",
      "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-7      524,288\n",
      "├─Wav2Vec2FeatureProjection: 1-2                   --\n",
      "|    └─LayerNorm: 2-2                              1,024\n",
      "|    └─Linear: 2-3                                 393,984\n",
      "|    └─Dropout: 2-4                                --\n",
      "├─Wav2Vec2Encoder: 1-3                             --\n",
      "|    └─Wav2Vec2PositionalConvEmbedding: 2-5        --\n",
      "|    |    └─Conv1d: 3-8                            4,719,488\n",
      "|    |    └─Wav2Vec2SamePadLayer: 3-9              --\n",
      "|    └─LayerNorm: 2-6                              1,536\n",
      "|    └─Dropout: 2-7                                --\n",
      "|    └─ModuleList: 2-8                             --\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-10             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-11             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-12             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-13             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-14             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-15             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-16             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-17             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-18             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-19             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-20             7,087,872\n",
      "|    |    └─Wav2Vec2EncoderLayer: 3-21             7,087,872\n",
      "===========================================================================\n",
      "Total params: 94,370,944\n",
      "Trainable params: 94,370,944\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "├─Wav2Vec2FeatureExtractor: 1-1                    --\n",
       "|    └─ModuleList: 2-1                             --\n",
       "|    |    └─Wav2Vec2GroupNormConvLayer: 3-1        6,144\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-2      786,432\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-3      786,432\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-4      786,432\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-5      786,432\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-6      524,288\n",
       "|    |    └─Wav2Vec2NoLayerNormConvLayer: 3-7      524,288\n",
       "├─Wav2Vec2FeatureProjection: 1-2                   --\n",
       "|    └─LayerNorm: 2-2                              1,024\n",
       "|    └─Linear: 2-3                                 393,984\n",
       "|    └─Dropout: 2-4                                --\n",
       "├─Wav2Vec2Encoder: 1-3                             --\n",
       "|    └─Wav2Vec2PositionalConvEmbedding: 2-5        --\n",
       "|    |    └─Conv1d: 3-8                            4,719,488\n",
       "|    |    └─Wav2Vec2SamePadLayer: 3-9              --\n",
       "|    └─LayerNorm: 2-6                              1,536\n",
       "|    └─Dropout: 2-7                                --\n",
       "|    └─ModuleList: 2-8                             --\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-10             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-11             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-12             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-13             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-14             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-15             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-16             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-17             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-18             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-19             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-20             7,087,872\n",
       "|    |    └─Wav2Vec2EncoderLayer: 3-21             7,087,872\n",
       "===========================================================================\n",
       "Total params: 94,370,944\n",
       "Trainable params: 94,370,944\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(raw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BROTHERS MARIETS WEK GOT SPENDTIME WITH MY SISTER IN LAW IS WELL AND I WAS ACTUALLY SUPPOSED TO SPEND ON SOME ADDITIONAL TIME AN ELE AH THAT WAS WHERE MY EUTO NETWORK IS BASED OUT OF AND SO I PLANNED AN TO GO VISIT TH OFFICES AND HAVE LUNCH WITH SOME PEOPLE INSTAFF ON'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from jiwer import wer\n",
    "\n",
    "\n",
    "librispeech_eval = load_dataset(\"librispeech_asr\", \"clean\", split=\"test\")\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\").to(\"cuda\")\n",
    "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "def map_to_array(batch):\n",
    "    speech, _ = sf.read(batch[\"file\"])\n",
    "    batch[\"speech\"] = speech\n",
    "    return batch\n",
    "\n",
    "librispeech_eval = librispeech_eval.map(map_to_array)\n",
    "\n",
    "def map_to_pred(batch):\n",
    "    input_values = tokenizer(batch[\"speech\"], return_tensors=\"pt\", padding=\"longest\").input_values\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values.to(\"cuda\")).logits\n",
    "\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "    transcription = tokenizer.batch_decode(predicted_ids)\n",
    "    batch[\"transcription\"] = transcription\n",
    "    return batch\n",
    "\n",
    "result = librispeech_eval.map(map_to_pred, batched=True, batch_size=1, remove_columns=[\"speech\"])\n",
    "\n",
    "print(\"WER:\", wer(result[\"text\"], result[\"transcription\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
