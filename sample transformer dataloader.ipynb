{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:35.996769Z",
     "start_time": "2021-03-24T22:27:35.338543Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_impressionv2_dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:41.217901Z",
     "start_time": "2021-03-24T22:27:36.860806Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, _ = load_impressionv2_dataset_split('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:41.229711Z",
     "start_time": "2021-03-24T22:27:41.222009Z"
    }
   },
   "outputs": [],
   "source": [
    "class TensorDatasetWithTransformer(th.utils.data.Dataset):\n",
    "    def __init__(self, tensor_dataset, transform=None):\n",
    "        self.tensor_dataset = tensor_dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.tensor_dataset[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tensor_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:41.248787Z",
     "start_time": "2021-03-24T22:27:41.231847Z"
    }
   },
   "outputs": [],
   "source": [
    "class SamplerTransform:\n",
    "    def __init__(self, srA, srF, srT, is_random=False):\n",
    "        self.srA = srA \n",
    "        self.srF = srF\n",
    "        self.srT = srT\n",
    "        self.is_random = is_random\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        audio, face, text, label = x\n",
    "        al = audio.shape[0]\n",
    "        fl = face.shape[0]\n",
    "        tl = text.shape[0]\n",
    "        assert al == 1526\n",
    "        assert fl == 459\n",
    "        assert tl == 60\n",
    "        assert self.srA <= al\n",
    "        assert self.srF <= fl\n",
    "        assert self.srT <= tl\n",
    "        \n",
    "        if not self.is_random:\n",
    "            a_idx = np.linspace(0, al-1, self.srA, dtype=int)\n",
    "            f_idx = np.linspace(0, fl-1, self.srF, dtype=int)\n",
    "            t_idx = np.linspace(0, tl-1, self.srT, dtype=int)\n",
    "        else:\n",
    "            a_idx = np.random.choice(al-1, self.srA, replace=False)\n",
    "            f_idx = np.random.choice(fl-1, self.srF, replace=False)\n",
    "            t_idx = np.random.choice(tl-1, self.srT, replace=False)\n",
    "            a_idx.sort()\n",
    "            f_idx.sort()\n",
    "            t_idx.sort()\n",
    "        audio_s = audio[a_idx, ]\n",
    "        face_s = face[f_idx, ]\n",
    "        text_s = text[t_idx, ]\n",
    "        \n",
    "        return audio_s, face_s, text_s, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:43.320955Z",
     "start_time": "2021-03-24T22:27:43.315067Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = TensorDatasetWithTransformer(train_ds, SamplerTransform(30, 30, 30, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:45.487623Z",
     "start_time": "2021-03-24T22:27:45.451763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([ 108,  254,  298,  305,  382,  401,  502,  546,  622,  664,  671,\n",
       "          687,  734,  736,  775,  828,  876,  943,  949,  994, 1003, 1043,\n",
       "         1211, 1276, 1293, 1419, 1461, 1477, 1514, 1518])],\n",
       " [array([ 65,  81,  83,  99, 112, 118, 122, 126, 128, 139, 158, 170, 181,\n",
       "         198, 216, 253, 288, 313, 329, 332, 346, 365, 375, 389, 401, 418,\n",
       "         432, 435, 448, 450])],\n",
       " [array([ 0,  3,  4,  5,  7,  8,  9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22,\n",
       "         24, 26, 30, 34, 35, 36, 38, 40, 44, 45, 51, 52, 57])],\n",
       " tensor([0.5514, 0.5000, 0.5275, 0.6505, 0.7444]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T22:27:54.491389Z",
     "start_time": "2021-03-24T22:27:54.471290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.7219, -0.6741, -0.0686,  ..., -1.0177,  1.2637, -1.1608],\n",
       "         [-1.7197, -0.6999,  0.0864,  ..., -0.1044,  0.2689, -0.3515],\n",
       "         [-1.7174, -0.6589,  0.6075,  ...,  0.8071, -0.5965,  0.4629],\n",
       "         ...,\n",
       "         [ 1.7259,  3.9920,  0.5464,  ...,  0.7302,  1.4042,  0.6708],\n",
       "         [ 1.7282,  4.0712,  0.7517,  ...,  0.7433,  1.5186,  0.6367],\n",
       "         [ 1.7304,  3.9432,  0.9267,  ...,  0.7425,  1.4939,  0.6272]]),\n",
       " tensor([[1.4787, 0.9806, 0.2581,  ..., 1.4020, 0.5203, 1.1110],\n",
       "         [1.7456, 1.5411, 0.3094,  ..., 1.7443, 0.5398, 1.3978],\n",
       "         [1.5188, 1.2019, 0.7119,  ..., 1.0248, 1.1424, 1.0761],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[-0.6210,  0.1200,  0.4032,  ..., -0.4498,  0.8524,  0.5574],\n",
       "         [ 0.2091,  0.0823, -0.2423,  ..., -0.0468,  1.3281,  0.6255],\n",
       "         [-0.1192,  0.5798,  1.4657,  ..., -0.0745,  0.4330, -0.0750],\n",
       "         ...,\n",
       "         [-0.0899,  0.3971,  0.3514,  ..., -0.1561,  0.3741,  0.1047],\n",
       "         [-0.1887,  0.3624,  0.1010,  ..., -0.1403,  0.2625,  0.1455],\n",
       "         [-0.1992,  0.3431,  0.1464,  ..., -0.1666,  0.2851,  0.1099]]),\n",
       " tensor([0.5514, 0.5000, 0.5275, 0.6505, 0.7444]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:51:31.826643Z",
     "start_time": "2021-03-24T14:51:31.818231Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1526, 24]),\n",
       " torch.Size([459, 512]),\n",
       " torch.Size([60, 768]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.shape, face.shape, text.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = audio.shape[0]\n",
    "fl = face.shape[0]\n",
    "tl = text.shape[0]\n",
    "\n",
    "assert al == 1526\n",
    "assert fl == 459\n",
    "assert tl == 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:50:19.524871Z",
     "start_time": "2021-03-24T14:50:19.515138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 3, 4, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:41:02.449297Z",
     "start_time": "2021-03-24T14:41:02.444321Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = TensorDatasetWithTransformer(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:50:52.175205Z",
     "start_time": "2021-03-24T14:50:52.157796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.7219e+00,  2.7733e+00, -8.3079e-04,  ...,  9.1841e-01,\n",
       "           2.5316e-01,  7.1584e-01],\n",
       "         [-1.7197e+00,  2.9463e+00,  3.3612e-01,  ...,  9.2970e-01,\n",
       "           3.9145e-01,  7.2137e-01],\n",
       "         [-1.7174e+00,  3.3067e+00,  6.6952e-01,  ...,  9.4596e-01,\n",
       "           4.8278e-01,  7.1030e-01],\n",
       "         ...,\n",
       "         [ 1.7259e+00,  1.6559e+00, -2.1393e-01,  ...,  6.6622e-01,\n",
       "          -2.3618e-01,  3.8720e-01],\n",
       "         [ 1.7282e+00,  2.0043e+00,  1.9660e-01,  ...,  7.1194e-01,\n",
       "          -2.1082e-01,  5.2063e-01],\n",
       "         [ 1.7304e+00,  2.3335e+00,  4.9705e-01,  ...,  7.1788e-01,\n",
       "          -3.0368e-01,  5.4108e-01]]),\n",
       " tensor([[1.0537, 0.4731, 0.2720,  ..., 0.8538, 0.8822, 1.0834],\n",
       "         [1.1153, 0.2641, 1.1917,  ..., 0.6055, 1.5155, 0.5456],\n",
       "         [1.1148, 0.0180, 1.0736,  ..., 1.0421, 1.7672, 0.2304],\n",
       "         ...,\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]),\n",
       " tensor([[-0.1528, -0.3227, -0.2083,  ..., -0.1850,  0.8483,  0.4139],\n",
       "         [ 0.6335, -0.1525,  0.5027,  ...,  0.2711,  0.8521,  0.5942],\n",
       "         [ 0.1439,  0.1660,  0.2751,  ...,  0.0264,  0.6697,  0.0868],\n",
       "         ...,\n",
       "         [-0.1634,  0.0276,  0.0400,  ..., -0.2316,  0.1508,  0.0370],\n",
       "         [-0.1559,  0.0973, -0.0256,  ..., -0.1699,  0.1738,  0.0285],\n",
       "         [ 0.2572,  0.2130,  0.2203,  ...,  0.5191,  0.0413, -0.0981]]),\n",
       " tensor([0.3925, 0.4271, 0.5165, 0.4757, 0.4667]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T14:53:39.130630Z",
     "start_time": "2021-03-24T14:53:39.124946Z"
    }
   },
   "outputs": [],
   "source": [
    "audio, face, text, label = ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
